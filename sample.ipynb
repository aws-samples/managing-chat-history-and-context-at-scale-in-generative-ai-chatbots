{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For a detailed explanation of the solution, please see the README.md file**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by installing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first create a boto3 bedrock client. We can use this client to issue API calls to Generative AI models available in Bedrock.\n",
    "\n",
    "Note: You can replace the profile_name with the profile name that is configured on your developer environment that has access to Bedrock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from botocore.config import Config\n",
    "import json\n",
    "import boto3\n",
    "REGION_NAME = 'us-east-1'\n",
    "retry_config = Config(\n",
    "        retries={\n",
    "            \"max_attempts\": 10,\n",
    "            \"mode\": \"standard\",\n",
    "        },\n",
    "    )\n",
    "session = boto3.Session(region_name=REGION_NAME, profile_name='default')\n",
    "bedrock_client = session.client(\n",
    "        service_name='bedrock-runtime',\n",
    "        config=retry_config\n",
    "    )\n",
    "\n",
    "print(\"boto3 Bedrock client successfully created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a resuable function that uses the client we created above to call Claude 3 Sonnet model on Bedrock. We can pass prompt and temperature to this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def call_bedrock_claude_3(prompt_text, temperature):\n",
    "    model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "    body = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt_text\n",
    "                        }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    body = json.dumps(body)\n",
    "    response = bedrock_client.invoke_model(\n",
    "            body=body, modelId=model_id\n",
    "        )\n",
    "    # Parse the response\n",
    "    response_lines = response['body'].readlines()\n",
    "    json_str = response_lines[0].decode('utf-8')\n",
    "    json_obj = json.loads(json_str)\n",
    "    result_text = json_obj['content'][0]['text']\n",
    "    \n",
    "    return {'role': 'assistant', 'content': result_text}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the access to Bedrock with a  sample api call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using Claude 3 Sonnet model\n",
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "prompt = \"Hello...\"\n",
    "\n",
    "# Call Bedrock and get the response\n",
    "response = call_bedrock_claude_3(prompt, 0.7)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **DynamoDB and Redis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this architecture, we use an Amazon DynamoDB table to persistently store all the chat messages. We create one table called \"ChatHistory\" with \"UserId\" as the partition key and \"Timestamp\" as the sort key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating DynamoDB Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "\n",
    "TABLE_NAME = 'ChatHistory'\n",
    "\n",
    "# Initialize the DynamoDB client\n",
    "dynamodb = boto3.client('dynamodb', region_name=REGION_NAME)\n",
    "\n",
    "# Create a DynamoDB table\n",
    "def create_dynamodb_table():\n",
    "    table_name = TABLE_NAME\n",
    "    try:\n",
    "        response = dynamodb.create_table(\n",
    "            TableName=table_name,\n",
    "            KeySchema=[\n",
    "                {\"AttributeName\": \"UserId\", \"KeyType\": \"HASH\"},  # Partition key\n",
    "                {\"AttributeName\": \"Timestamp\", \"KeyType\": \"RANGE\"}  # Sort key\n",
    "            ],\n",
    "            AttributeDefinitions=[\n",
    "                {\"AttributeName\": \"UserId\", \"AttributeType\": \"S\"},  \n",
    "                {\"AttributeName\": \"Timestamp\", \"AttributeType\": \"S\"}, \n",
    "            ],\n",
    "            ProvisionedThroughput={\n",
    "                \"ReadCapacityUnits\": 5,\n",
    "                \"WriteCapacityUnits\": 5\n",
    "            }\n",
    "        )\n",
    "        print(f\"Creating table {table_name}...\")\n",
    "        dynamodb.get_waiter('table_exists').wait(TableName=table_name)\n",
    "        print(f\"Table {table_name} has been created.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating table: {e}\")\n",
    "\n",
    "# Call the function to create the table \n",
    "create_dynamodb_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we install redis python package that will allow us to read or write from the cache. \n",
    "\n",
    "Note: This sample assumes there's a Redis cache already created and you have access to the endpoint. You can use AWS Elasticache to easily create serverless Redis Caches. Please visit this url to learn more: https://aws.amazon.com/blogs/aws/amazon-elasticache-serverless-for-redis-and-memcached-now-generally-available/\n",
    "\n",
    "Note: If you are using Elasticache Redis Serverless, you have to run this sample from the same VPC as the cache is in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install redis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next block we create two handy functions to test the connection to Redis and DynamoDB. We will add some test data and try retrieving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import redis\n",
    "import boto3\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration for Redis and DynamoDB\n",
    "\n",
    "redis_host = \"<REPLACE_WITH_REDIS_ENDPOINT>\"\n",
    "redis_port = \"<REPLACE_WITH_REDIS_PORT>\"\n",
    "dynamodb_table = TABLE_NAME\n",
    "aws_region = REGION_NAME\n",
    "\n",
    "# Initialize Redis client\n",
    "redis_client = redis.Redis(host=redis_host, port=redis_port, decode_responses=True, ssl=True)\n",
    "\n",
    "# Initialize DynamoDB client\n",
    "dynamodb_client = boto3.client('dynamodb', region_name=REGION_NAME)\n",
    "\n",
    "\n",
    "# Test function for Redis connection\n",
    "def test_redis_connection():\n",
    "    try:\n",
    "        # Add a test message to Redis\n",
    "        user_id = \"test_user_redis\"\n",
    "        message_text = \"Hello from Redis!\"\n",
    "        timestamp = datetime.utcnow().isoformat()\n",
    "        message = {\"content\": message_text, \"timestamp\": timestamp}\n",
    "        stack_key = f\"{user_id}:stack\"\n",
    "        redis_client.rpush(stack_key, json.dumps(message))\n",
    "\n",
    "        # Retrieve and print the messages\n",
    "        retrieved_messages = redis_client.lrange(stack_key, 0, -1)\n",
    "        print(f\"Retrieved messages from Redis for {user_id}:\")\n",
    "        for msg in retrieved_messages:\n",
    "            print(json.loads(msg))\n",
    "    except Exception as e:\n",
    "        print(f\"Error in Redis connection test: {e}\")\n",
    "\n",
    "\n",
    "# Test function for DynamoDB connection\n",
    "def test_dynamodb_connection():\n",
    "    try:\n",
    "        # Add a test message to DynamoDB\n",
    "        user_id = \"test_user_dynamodb\"\n",
    "        message_text = \"Hello from DynamoDB!\"\n",
    "        timestamp = datetime.utcnow().isoformat()\n",
    "        dynamodb_client.put_item(\n",
    "            TableName=TABLE_NAME,\n",
    "            Item={\n",
    "                \"UserId\": {\"S\": user_id},\n",
    "                \"Timestamp\": {\"S\": timestamp},\n",
    "                \"Content\": {\"S\": message_text},\n",
    "                \"BatchId\": {\"N\": \"1\"}\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Query and print the messages\n",
    "        response = dynamodb_client.query(\n",
    "            TableName=dynamodb_table,\n",
    "            KeyConditionExpression=\"UserId = :user\",\n",
    "            ExpressionAttributeValues={\":user\": {\"S\": user_id}}\n",
    "        )\n",
    "        print(f\"Retrieved messages from DynamoDB for {user_id}:\")\n",
    "        for item in response['Items']:\n",
    "            print({\n",
    "                \"UserId\": item[\"UserId\"][\"S\"],\n",
    "                \"Timestamp\": item[\"Timestamp\"][\"S\"],\n",
    "                \"Content\": item[\"Content\"][\"S\"],\n",
    "                \"BatchId\": item[\"BatchId\"][\"N\"]\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Error in DynamoDB connection test: {e}\")\n",
    "\n",
    "\n",
    "# Run the test functions\n",
    "test_redis_connection()\n",
    "test_dynamodb_connection()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing purposes, we can also create two utility functions to completely cleanup data from Redis and DynamoDB. \n",
    "\n",
    "**Please note:** Use these functions with caution, only while testing. These can delete important data in production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import redis\n",
    "\n",
    "def clear_all_redis_data(redis_host, redis_port, redis_password=None):\n",
    "    try:\n",
    "        # Connect to Redis\n",
    "        redis_client = redis.Redis(host=redis_host, port=redis_port, decode_responses=True, ssl=True)\n",
    "        \n",
    "        # Flush all keys in the current database\n",
    "        redis_client.flushdb()\n",
    "        print(\"Successfully cleared all data in the current Redis database.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error clearing Redis data: {e}\")\n",
    "\n",
    "# Call the function to clear all data in Redis\n",
    "clear_all_redis_data(redis_host, 6379, \"your-redis-password\")  # Remove password if not used\n",
    "\n",
    "import boto3\n",
    "\n",
    "def clear_all_dynamodb_data(table_name, aws_region):\n",
    "    dynamodb_client = boto3.client('dynamodb', region_name=aws_region)\n",
    "    dynamodb_resource = boto3.resource('dynamodb', region_name=aws_region)\n",
    "    table = dynamodb_resource.Table(table_name)\n",
    "    \n",
    "    try:\n",
    "        # Scan to get all items\n",
    "        response = table.scan()\n",
    "        items = response['Items']\n",
    "\n",
    "        # Use batch writer to delete items in batches\n",
    "        with table.batch_writer() as batch:\n",
    "            for item in items:\n",
    "                batch.delete_item(Key={\"UserId\": item['UserId'], \"Timestamp\": item['Timestamp']})\n",
    "        \n",
    "        print(f\"Successfully cleared all data from DynamoDB table: {table_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error clearing DynamoDB data: {e}\")\n",
    "\n",
    "# Call the function to clear all data in DynamoDB\n",
    "clear_all_dynamodb_data(TABLE_NAME, REGION_NAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### **Chat History Summarization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every 20 messages in a user's chat, we summarize them using an LLM (Claude 3). The following code creates a simple summarization prompt and a function to call the LLM. You can modify the prompt for your particular use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summarize_prompt = \"\"\"\n",
    "Given a history of chat messages, summarize the conversation between user and AI in to one paragraph of not more than 250 words.\n",
    "Summarize all user messages in to one paragraph and all AI messages in to another paragraph.\n",
    "User: \n",
    "AI: \n",
    "\n",
    "Message history:\n",
    "{conversation}\n",
    "\n",
    "Instructions:\n",
    "\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "def summarize_chat_history(messages):\n",
    "    # Combine all user messages (20 messages are passed to this function at a time)\n",
    "    summary = \" \".join([str(msg) for msg in messages])\n",
    "    # Generate the prompt for summarization\n",
    "    prompt = summarize_prompt.format(conversation=summary)\n",
    "    # Call the Bedrock model to generate the summary\n",
    "    response = call_bedrock_claude_3(prompt, 0.7)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create the ChatManager class which handles the new message workflow, the summarization and chat history retrieval workflows.\n",
    "\n",
    "Please read inline comments for explanation of each function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import redis\n",
    "import boto3\n",
    "import json\n",
    "import threading\n",
    "from datetime import datetime\n",
    "import boto3\n",
    "from boto3.dynamodb.conditions import Key\n",
    "\n",
    "\n",
    "class ChatManager:\n",
    "    def __init__(self, redis_host, redis_port, dynamodb_table, region):\n",
    "        # Connect to Redis\n",
    "        self.redis_client = redis.Redis(host=redis_host, port=redis_port, decode_responses=True, ssl=True)\n",
    "        self.lock = threading.Lock()\n",
    "        \n",
    "        # Set up DynamoDB client and table\n",
    "        self.dynamodb_client = boto3.client('dynamodb', region_name=region)\n",
    "        self.dynamodb_resource = boto3.resource('dynamodb', region_name=region)\n",
    "        self.dynamodb_table = dynamodb_table\n",
    "        self.region = region\n",
    "\n",
    "    def count_messages_with_batch(self, stack_key, batch_id):\n",
    "        \"\"\"\n",
    "        Count the number of messages in the specified stack that have the given batch_id.\n",
    "        \"\"\"\n",
    "        count = 0\n",
    "        # Retrieve all messages from the Redis stack\n",
    "        messages = self.redis_client.lrange(stack_key, 0, -1)\n",
    "\n",
    "        # Count messages with the specified batch_id\n",
    "        for msg in messages:\n",
    "            message = json.loads(msg)\n",
    "            if message[\"batch_id\"] == batch_id:\n",
    "                count += 1\n",
    "        return count\n",
    "\n",
    "    def handle_new_message(self, user_id, message_text):\n",
    "        with self.lock:\n",
    "            # Define keys for Redis\n",
    "            stack_key = f\"{user_id}:stack\" # Stores individual messages for a particular user\n",
    "            batch_id_key = f\"{user_id}:batch_id\" # Stores the current batch ID for a user\n",
    "            \n",
    "            # Retrieve the current batch ID from Redis, or initialize it\n",
    "            batch_id = self.redis_client.get(batch_id_key)\n",
    "            if batch_id is None:\n",
    "                batch_id = 1\n",
    "            else:\n",
    "                batch_id = int(batch_id)\n",
    "\n",
    "            # Create a new message dictionary with a timestamp\n",
    "            timestamp = datetime.utcnow().isoformat()\n",
    "            message = {\"batch_id\": batch_id, \"content\": message_text, \"timestamp\": timestamp}\n",
    "            \n",
    "            # Add the new message to the cache stack for the user. When the stack reaches 20 messages, a summary is created.\n",
    "            self.redis_client.rpush(stack_key, json.dumps(message))\n",
    "\n",
    "            # Persist the message to DynamoDB\n",
    "            self.dynamodb_client.put_item(\n",
    "                TableName=self.dynamodb_table,\n",
    "                Item={\n",
    "                    \"UserId\": {\"S\": user_id},\n",
    "                    \"Timestamp\": {\"S\": timestamp},\n",
    "                    \"Content\": {\"S\": message_text},\n",
    "                    \"BatchId\": {\"N\": str(batch_id)}\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # Check if the stack has 20 messages for the current batch ID\n",
    "            count = self.count_messages_with_batch(stack_key, batch_id)\n",
    "            if count == 4:\n",
    "                threading.Thread(target=self._create_summary, args=(user_id, batch_id)).start()\n",
    "                self.redis_client.set(batch_id_key, batch_id + 1)\n",
    "\n",
    "    def _create_summary(self, user_id, batch_id):\n",
    "        with self.lock:\n",
    "            # Retrieve all messages for the user with the specified batch ID\n",
    "            stack_key = f\"{user_id}:stack\"\n",
    "            all_messages = [json.loads(msg) for msg in self.redis_client.lrange(stack_key, 0, -1)]\n",
    "            messages = [msg for msg in all_messages if msg[\"batch_id\"] == batch_id]\n",
    "\n",
    "            # Create a summary of those messages\n",
    "            summary_content = summarize_chat_history(messages)\n",
    "            summary = {\"batch_id\": batch_id, \"content\": summary_content, \"count\": len(messages)}\n",
    "\n",
    "            # Store the summary in Redis\n",
    "            summary_key = f\"{user_id}:summary\"\n",
    "            self.redis_client.set(summary_key, json.dumps(summary))\n",
    "\n",
    "            # Gather all messages from the cache which have not been summarized yet\n",
    "            remaining_messages = [msg for msg in all_messages if msg[\"batch_id\"] != batch_id]\n",
    "\n",
    "            # Clear the stack and repopulate with the remaining messages\n",
    "            self.redis_client.delete(stack_key)\n",
    "            for msg in remaining_messages:\n",
    "                self.redis_client.rpush(stack_key, json.dumps(msg))\n",
    "\n",
    "    # Get the chat history for a user. This fetches the most recent summary and messages which are not summarized yet.\n",
    "    def get_chat_history(self, user_id):\n",
    "        \n",
    "\n",
    "        # Retrieve the summary for the user and add it to the history\n",
    "        summary_key = f\"{user_id}:summary\"\n",
    "        summary = self.redis_client.get(summary_key)\n",
    "        history = []\n",
    "        \n",
    "        if summary is not None:\n",
    "            history.append(json.loads(summary))\n",
    "\n",
    "        # Retrieve all messages from the Redis stack which have not been summarized. This batch will be summarized when it reaches 20 messages.\n",
    "        # Combine the remaining messages with the summary\n",
    "        stack_key = f\"{user_id}:stack\"\n",
    "        remaining_messages = [json.loads(msg) for msg in self.redis_client.lrange(stack_key, 0, -1)]\n",
    "        history.extend(remaining_messages)\n",
    "\n",
    "        return history\n",
    "\n",
    "    # We use this method to load the last 20 messages for a user from DynamoDB and populate the Redis cache. This is useful when the cache is reset or when the application is restarted.\n",
    "    def load_messages_from_dynamodb(self, user_id):\n",
    "       \n",
    "        table = self.dynamodb_resource.Table(TABLE_NAME)\n",
    "        \n",
    "        # Query the table with a limit of 20 items\n",
    "        response = table.query(\n",
    "            KeyConditionExpression=Key('UserId').eq(user_id),\n",
    "            Limit=20,\n",
    "            ScanIndexForward=False # Retrieve in descending order of the sort key: Timestamp\n",
    "        )\n",
    "\n",
    "        # Reset Redis state and populate messages\n",
    "        stack_key = f\"{user_id}:stack\"\n",
    "        summary_key = f\"{user_id}:summary\"\n",
    "        self.redis_client.delete(stack_key)\n",
    "        self.redis_client.delete(summary_key)\n",
    "        \n",
    "        # Rehydrate redis cache\n",
    "        for item in reversed(response['Items']):\n",
    "            print(\"Reloading:\"+str(item))\n",
    "            message = {\"batch_id\": int(item['BatchId']), \"content\": item['Content'], \"timestamp\": item['Timestamp']}\n",
    "            self.redis_client.rpush(stack_key, json.dumps(message))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we instantiate the class. To demonstrate the new messages and summarization workflows, we load sample conversations. Please check sample_conversations.py for a sample chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "chat_manager = ChatManager(redis_host, redis_port, dynamodb_table, REGION_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Sample Messages. Summarization worflow gets triggered when we load 20 messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sample_conversation import conversation\n",
    "\n",
    "for c in conversation:\n",
    "    chat_manager.handle_new_message(\"user1\", str(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's fetch the chat history at this point and youll see that it fetches most recent messages which have not been summarized (because the batch did not reach count 20) and the most recent summary. Notice the bacth id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = chat_manager.get_chat_history(\"user1\")\n",
    "pprint.pprint(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use a loop to create a simple chatbot. On every new message, we first fetch the history, combine it with the question and send it to the LLM to get a response. Once we get a response, we add the user's message and LLM's response to Redis and DynamoDB accordingly using handle_new_message function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_prompt = \"\"\"\n",
    "Given a question and chat history, answer the question in the context of the conversation.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "for i in range(6):\n",
    "    question = input()\n",
    "    message = {\"role\":\"user\", \"content\": question}\n",
    "    history = str(chat_manager.get_chat_history(\"user1\"))\n",
    "    prompt = question_prompt.format(chat_history=history, question=question)\n",
    "    response = call_bedrock_claude_3(prompt, 0.7)\n",
    "    chat_manager.handle_new_message(\"user1\", str(message))\n",
    "    chat_manager.handle_new_message(\"user1\", str(response))\n",
    "    print(response)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can now see the chat history again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = chat_manager.get_chat_history(\"user1\")\n",
    "pprint.pprint(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the cache is deleted and we want to rehydrate cache with previous 20 messages, we can call the below method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_manager.load_messages_from_dynamodb('user1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
